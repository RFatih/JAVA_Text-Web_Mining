package trainset;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashSet;
import java.util.Hashtable;
import java.util.List;
import java.util.Set;

import zemberek.tokenization.TurkishTokenizer;
public class Training {
	private Set<String> frequencies = new HashSet<>();
	private List<String> RemovedPD = new ArrayList<String>();

	public List<String> getRemovedPD() {
		return RemovedPD;
	}

	public void setRemovedPD(List<String> removedPD) {
		RemovedPD = removedPD;
	}

	public Set<String> getFrequencies() {
		return frequencies;
	}

	public void setFrequencies(Set<String> frequencies) {
		this.frequencies = frequencies;
	}

	public void Train(String file, String fileName) throws IOException {
		// TODO Auto-generated method stub

		TextReader reader= new TextReader();
		String sentences=reader.readText(file, "ISO-8859-9","");
		
		String stopWords=reader.readText("/media/fatih/4602A96202A957A7/new/Study_School/metin-madenciligi/stop-words","UTF-8"," ");
       // TurkishSentenceExtractor extractor = TurkishSentenceExtractor.DEFAULT;
        sentences=sentences.toLowerCase();
        //List<String> cumleler = extractor.fromParagraph(sentences);
        //System.out.println(cumleler);
        System.out.println("Tokenlara ayırmaya başladı...");
        TurkishTokenizer tokenizer = TurkishTokenizer.DEFAULT;
        List<String> tokens = tokenizer.tokenizeToStrings(sentences);
        List<String> sTokens = tokenizer.tokenizeToStrings(stopWords);
        
        //System.out.println(tokens);
       // System.out.println(tokens);
       // System.out.println(sTokens);
        System.out.println("Köklerine ayırmaya başladı...");
        Stemming stemming = new Stemming();
        List<String> stemmedResult = stemming.stems(tokens);
        
       
       System.out.println("Gereksiz kelimeler atılıyor..");
        StopWords stopWords2= new StopWords();
        List<String> removedTokens = stopWords2.removeStopWords(stemmedResult, sTokens);
       // System.out.println(tokens.size()+" "+ removedTokens.size());
       //System.out.println(removedTokens);
        
        System.out.println("Sayı ve işaretler atılıyor..");
        PunctuationAndDigits pD= new PunctuationAndDigits();
        List<String> RemovedPD = pD.removePD(removedTokens);
       // System.out.println(RemovedPD);
        
        this.setRemovedPD(RemovedPD);
      
        Set<String> frequencies = new HashSet<>(RemovedPD);
        Hashtable<String, String> my_dict = new Hashtable<String, String>();
        for (String uniqeWord : frequencies)
        {
        	my_dict.put(uniqeWord, Collections.frequency(RemovedPD, uniqeWord)+"");
        }
		 
        System.out.println(frequencies.size());

        FileWriter myWriter = new FileWriter(fileName+".txt");
        myWriter.write(RemovedPD.toString());
        myWriter.close();
        myWriter = new FileWriter("Dict"+".txt");
        myWriter.write(my_dict.toString());
        myWriter.close();
	}

}
